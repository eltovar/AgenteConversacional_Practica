"""
Servicio de RAG (Retrieval-Augmented Generation) con bÃºsqueda semÃ¡ntica.
Usa pgvector para almacenamiento de embeddings y bÃºsqueda por similitud.
"""

import time
from typing import Dict, List, Any
from langchain_core.documents import Document
from logging_config import logger
from rag.data_loader import load_and_chunk_documents, load_placeholder_documents
from rag.vector_store import pg_vector_store

# ===== LISTA DE NÃšMEROS OBSOLETOS =====
# Estos nÃºmeros fueron reemplazados y NO deben aparecer en respuestas
OBSOLETE_PHONE_NUMBERS = [
    "322 502 1493",  # NÃºmero viejo del Ã¡rea de contratos
    "3225021493",    # Sin espacios
    "+573225021493", # Con cÃ³digo paÃ­s
]


class RAGService:
    """
    Servicio central de RAG. Orquesta la bÃºsqueda y gestiÃ³n de la Base de Conocimiento (KB).

    NOTA CRÃTICA: Se eliminÃ³ la inicializaciÃ³n perezosa (lazy) para asegurar que
    la carga e indexaciÃ³n pesada ocurra en el startup del servidor, evitando timeouts.
    """
    KNOWLEDGE_BASE_DIR = "knowledge_base"
    CHUNK_SIZE = 500
    CHUNK_OVERLAP = 100

    def __init__(self):
        """
        La inicializaciÃ³n pesada de la DB y la carga de KB
        se debe hacer explÃ­citamente a travÃ©s de reload_knowledge_base()
        en el evento de startup del servidor (ver app.py).
        """
        logger.info("[RAG] RAGService inicializado. La Base de Conocimiento debe ser cargada al inicio.")

    def reload_knowledge_base(self) -> Dict[str, Any]:
        """
        FunciÃ³n pÃºblica para forzar la carga e indexaciÃ³n de la Base de Conocimiento.
        Debe ser llamada durante el inicio del servidor (startup).
        """
        start_time = time.time()
        logger.info(f"[RAG] Iniciando recarga e indexaciÃ³n completa de la KB desde {self.KNOWLEDGE_BASE_DIR}...")

        try:
            # 1. Asegurar que la DB estÃ© conectada (inicializar PgVectorStore)
            pg_vector_store.initialize_db()

            # 2. Cargar y dividir documentos
            chunks = load_and_chunk_documents(
                base_dir=self.KNOWLEDGE_BASE_DIR,
                chunk_size=self.CHUNK_SIZE,
                chunk_overlap=self.CHUNK_OVERLAP
            )

            # 3. Fallback a placeholder si KB vacÃ­a
            if not chunks:
                logger.warning("[RAG] Base de conocimiento vacÃ­a. Cargando documentos placeholder.")
                chunks = load_placeholder_documents()

            # 4. LIMPIAR ÃNDICE ANTERIOR (DELETE total)
            logger.info(f"[RAG] Limpiando {pg_vector_store.collection_name} para re-indexaciÃ³n...")
            self._clear_vector_store()

            # 5. Indexar chunks nuevos
            logger.info(f"[RAG] Indexando {len(chunks)} chunks en pgvector. Â¡Esto puede ser lento!")
            ids = pg_vector_store.add_documents(chunks)

            end_time = time.time()
            duration = end_time - start_time
            logger.info(f"[RAG] âœ… IndexaciÃ³n completa en {duration:.2f} segundos. Chunks indexados: {len(ids)}")

            return {
                "status": "success",
                "chunks_indexed": len(ids),
                "duration": duration,
                "message": f"Base de conocimiento actualizada. {len(ids)} chunks indexados en {duration:.2f}s."
            }

        except Exception as e:
            logger.error(f"[RAG] âŒ Error CRÃTICO durante la recarga de la Base de Conocimiento: {e}", exc_info=True)
            return {
                "status": "error",
                "chunks_indexed": 0,
                "message": str(e)
            }

    def _clear_vector_store(self) -> None:
        """
        Limpia el vector store eliminando documentos antiguos.
        Ejecuta DELETE directo en PostgreSQL para evitar duplicados.
        """
        try:
            import psycopg

            logger.info("[RAG] Limpiando Ã­ndice vectorial anterior...")

            # Obtener connection string (pg_vector_store ya estÃ¡ importado en el scope global)
            connection_string = pg_vector_store.connection_string
            collection_name = pg_vector_store.collection_name

            # Conectar y ejecutar DELETE
            if connection_string is None:
                raise ValueError("DATABASE_URL no estÃ¡ configurada")
            
            with psycopg.connect(connection_string) as conn:
                with conn.cursor() as cursor:
                    # Eliminar todos los documentos de la colecciÃ³n
                    cursor.execute(
                        "DELETE FROM langchain_pg_embedding WHERE cmetadata->>'collection_name' = %s",
                        (collection_name,)
                    )
                    deleted_count = cursor.rowcount
                    conn.commit()

                    logger.info("[RAG] Vector store limpiado: %d documentos eliminados", deleted_count)

        except Exception as e:
            # No es fatal si falla la limpieza, solo logueamos warning
            logger.warning("[RAG] No se pudo limpiar vector store: %s", e)

    def _validate_response_no_obsolete_numbers(self, response: str) -> str:
        """
        ðŸ›¡ï¸ VALIDACIÃ“N DE SEGURIDAD: Verifica que la respuesta no contenga nÃºmeros telefÃ³nicos obsoletos.
        
        Esta es una medida preventiva para evitar servir informaciÃ³n desactualizada.
        Si se detecta un nÃºmero obsoleto, se lanza una excepciÃ³n.
        
        Args:
            response: Texto de respuesta del RAG
            
        Returns:
            str: La respuesta validada (o excepciÃ³n si contiene nÃºmeros obsoletos)
            
        Raises:
            RuntimeError: Si se detecta un nÃºmero obsoleto en la respuesta
        """
        for obsolete_num in OBSOLETE_PHONE_NUMBERS:
            if obsolete_num in response:
                error_msg = (
                    f"ðŸš¨ NÃšMERO OBSOLETO DETECTADO EN RESPUESTA: {obsolete_num} | "
                    f"Este nÃºmero fue reemplazado y NO debe servirse a usuarios."
                )
                logger.critical(error_msg)
                raise RuntimeError(error_msg)
        
        return response

    def search_knowledge(self, document_path: str, query: str, k: int = 5) -> str:
        """
        Realiza la bÃºsqueda de similitud en el vector store, filtrando por el documento de origen.

        Args:
            document_path: La ruta del documento a filtrar (usado como metadata 'source').
            query: La pregunta del usuario.

        Returns:
            str: El contexto relevante concatenado o un mensaje de error.
        """
        # Ya no necesitamos _ensure_db_initialized, ya que se hizo en el startup.

        try:
            logger.debug(f"[RAG] BÃºsqueda en '{document_path}' con query: '{query}'")

            # Normalizar ruta para comparaciÃ³n
            normalized_doc_path = document_path.replace("\\", "/")

            # Usar filtrado nativo de PGVector (mÃ¡s eficiente que filtrar en Python)
            filtered_results = pg_vector_store.similarity_search(
                query,
                k=k,
                filter={"source": normalized_doc_path}
            )

            if not filtered_results:
                logger.warning(f"[RAG] No se encontraron resultados para '{document_path}'")
                return f"[ERROR] Documento '{document_path}' no disponible en el Ã­ndice actual."

            # Formatear resultados
            context_parts = [doc.page_content.strip() for doc in filtered_results]
            formatted_context = "\n".join(context_parts)

            # ðŸ›¡ï¸ Validar que no contenga nÃºmeros obsoletos
            self._validate_response_no_obsolete_numbers(formatted_context)

            logger.debug("[RAG] Encontrados %d chunks relevantes", len(filtered_results))
            return formatted_context

        except (ValueError, RuntimeError) as e:
            logger.error("[RAG] Error en bÃºsqueda: %s", e, exc_info=True)
            return f"[ERROR] Error al buscar en '{document_path}': {str(e)}"

    def semantic_search(self, query: str, k: int = 5) -> List[Document]:
        """
        BÃºsqueda semÃ¡ntica pura (sin filtrado por documento).
        """
        # Ya no se requiere _ensure_db_initialized (se hizo en startup)

        try:
            logger.debug(f"[RAG] BÃºsqueda semÃ¡ntica: '{query}' (top-{k})")
            results = pg_vector_store.similarity_search(query, k=k)
            logger.debug(f"[RAG] Encontrados {len(results)} resultados")
            return results

        except Exception as e:
            logger.error(f"[RAG] Error en bÃºsqueda: {e}", exc_info=True)
            return []

    def get_context_for_query(self, query: str, k: int = 3) -> str:
        """
        Obtiene contexto relevante formateado para el LLM (bÃºsqueda global).
        """
        documents = self.semantic_search(query, k=k)

        if not documents:
            logger.warning("[RAG] No se encontrÃ³ contexto relevante")
            return "[Sin contexto disponible]"

        # Formatear documentos para el LLM
        context_parts = []
        for i, doc in enumerate(documents, 1):
            source = doc.metadata.get("source", "desconocido")
            content = doc.page_content.strip()
            context_parts.append(f"[Fuente {i}: {source}]\n{content}")

        formatted_context = "\n\n".join(context_parts)
        logger.debug(f"[RAG] Contexto generado: {len(formatted_context)} caracteres")

        return formatted_context


# Instancia global
rag_service = RAGService()

# FunciÃ³n main para testing/validaciÃ³n manual
def main():
    """
    FunciÃ³n principal para validar la carga e indexaciÃ³n manualmente.
    Ejecutar: python rag.py
    """
    print("=" * 60)
    print("VALIDACIÃ“N DE INDEXACIÃ“N RAG")
    print("=" * 60)

    print("\n[1/3] Forzando recarga de base de conocimiento...")
    result = rag_service.reload_knowledge_base()
    print(f"Resultado: {result}")

    print("\n[2/3] Realizando bÃºsqueda de prueba (semÃ¡ntica global)...")
    query = "Â¿CuÃ¡l es la misiÃ³n de la empresa?"
    results = rag_service.semantic_search(query, k=3)
    
    print(f"\nResultados para '{query}':")
    for i, doc in enumerate(results, 1):
        print(f"\n--- Resultado {i} ---")
        print(f"Fuente: {doc.metadata.get('source', 'N/A')}")
        print(f"Contenido: {doc.page_content[:200]}...")

    print("\n[3/3] Obteniendo contexto formateado...")
    context = rag_service.get_context_for_query(query, k=2)
    print("\nContexto generado:")
    print(context[:500] + "..." if len(context) > 500 else context)

    print("\n" + "=" * 60)
    print("âœ… VALIDACIÃ“N COMPLETADA")
    print("=" * 60)


if __name__ == "__main__":
    main()